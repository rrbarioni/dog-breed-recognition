{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "initial_enroller.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uddTbvSraJRk",
        "colab_type": "text"
      },
      "source": [
        "# Computing initial dog embeddings from train set\n",
        "\n",
        "This code aim to generate embeddings from the training dataset, so it can be used to dynamically generate dog breed classifiers. After the training of the embeddings extraction model is done, this computation is only needed to be performed once."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfxLF3aTaUAf",
        "colab_type": "text"
      },
      "source": [
        "## Accessing the Dog Breed Recognition dataset\n",
        "\n",
        "I have created a directory called \"dog-breed-recognition\". There, I have put the directory called \"dogs\" as refering to the dataset itself. For training, it is only used the samples contained at \"train\" directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyQuTFQ6bLay",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a213e1f4-dcfe-4c8c-df27-093dbb97cf47"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "root = '/content/drive/My Drive/Colab Notebooks/dog-breed-recognition'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5bYpRiIj2Xa",
        "colab_type": "text"
      },
      "source": [
        "## Importing basic Python libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2s2ecclbTeD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import tqdm\n",
        "import random\n",
        "import copy\n",
        "from six.moves import cPickle as pickle\n",
        "\n",
        "from PIL import Image\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tq0XMzHCj63b",
        "colab_type": "text"
      },
      "source": [
        "## Importing PyTorch library\n",
        "\n",
        "For GPU usage, go to \"Edit > Notebook Settings\" and make sure the hardware accelerator is set to GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTqRvLgFbUHl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "# Creating a PyTorch device, so that inputs, outputs and models are apllied to\n",
        "#   the available GPU\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wwtYKIgkEQZ",
        "colab_type": "text"
      },
      "source": [
        "## Setting up initial enrolling parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzorzqPccJZy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# `dataset_path ` represents the path containing the dog breed images (from the\n",
        "#   initial 100 classes)\n",
        "dataset_path = os.path.join(root, 'dogs', 'train')\n",
        "\n",
        "# `model_ckpt_path` encodes the path to the file containing the weights of the\n",
        "#   embeddings extraction model\n",
        "model_ckpt_path = os.path.join(root, 'models', 'embedder.pth')\n",
        "\n",
        "# `initial_enroll_path` represents the path where to save the embeddings of the\n",
        "#   set of images representing the initial 100 classes\n",
        "initial_enroll_path = os.path.join(root, 'models', 'initial_enroll.pkl')\n",
        "\n",
        "# Batch size which to compute the embeddings\n",
        "batch_size = 32\n",
        "\n",
        "# Number of workers for multiprocessing the images loading\n",
        "n_workers = 8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJHQ251PmKvK",
        "colab_type": "text"
      },
      "source": [
        "## Setting up embedder model loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qe5abQhJdZN-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def embedder_model(n_embeddings):\n",
        "  '''\n",
        "  Generates a CNN ResNet50-based embedder.\n",
        "  \n",
        "  Parameters\n",
        "  ----------\n",
        "  n_embeddings\n",
        "    number of embeddings to be outputted\n",
        "  \n",
        "  Returns\n",
        "  -------\n",
        "  x : torch.nn\n",
        "    the model\n",
        "  '''\n",
        "\n",
        "  # First, `x` is a new ResNet50 CNN model\n",
        "  x = torchvision.models.resnet50(pretrained=False)\n",
        "  \n",
        "  # Change the final fully connected layer so that the output size\n",
        "  #   matches the desired `n_embeddings` size. Also, apply sigmoid\n",
        "  #   function\n",
        "  x.fc = torch.nn.Sequential(\n",
        "      torch.nn.Linear(2048, n_embeddings),\n",
        "      torch.nn.Sigmoid())\n",
        "\n",
        "  return x\n",
        "\n",
        "# Load checkpoint of the trained embedding extractor\n",
        "model_ckpt = torch.load(model_ckpt_path, map_location=device)\n",
        "\n",
        "# Get the number of embeddings of the trained model\n",
        "n_embeddings = model_ckpt['n_embeddings']\n",
        "\n",
        "# Get the weights of the trained model\n",
        "state_dict = model_ckpt['state_dict']\n",
        "\n",
        "# Initialize the embedder architecture\n",
        "model = embedder_model(n_embeddings)\n",
        "\n",
        "# Load the weights into the embedder\n",
        "model.load_state_dict(state_dict)\n",
        "model.eval()\n",
        "model = torch.jit.script(model).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H340GJQ4mQar",
        "colab_type": "text"
      },
      "source": [
        "## Initial dataset loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZWzvcDAeeg4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ImageDataset(torch.utils.data.Dataset):\n",
        "  \"\"\"\n",
        "  A class to read the set of images from the initial 100 classes.\n",
        "  \n",
        "  Attributes\n",
        "  ----------\n",
        "  classes : list<str>\n",
        "    list of classes (dog breeds) presented in the 100-classes initial dataset\n",
        "  instances_path : list<str>\n",
        "    list of paths of each instance of the 100-classes initial dataset\n",
        "  instances_class : list<int>\n",
        "    list of dog breed labels of each instance of the 100-classes initial dataset\n",
        "  transform : torch.transform\n",
        "    input preprocessing pipeline\n",
        "\n",
        "  Data descriptors\n",
        "  ----------------\n",
        "  __getitem__\n",
        "    Gets the model's input and the respective dog breed index from a dataset\n",
        "      instance.\n",
        "\n",
        "  __len__\n",
        "    Gets the number of samples presented in the set of images from the initial\n",
        "      100 classes.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, dataset_path):\n",
        "    '''\n",
        "    Constructs all the attributes for the image loader object.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    dataset_path : str\n",
        "      root of the 100-classes initial dataset\n",
        "    '''\n",
        "\n",
        "    # `dataset_path` divides the dataset in a list of directories, where each\n",
        "    #   directory represent a class (dog breed). When listing the presented\n",
        "    #   directories in `dataset_path`, `self.classes` will contain the list of\n",
        "    #   dog breeds presented in the dataset\n",
        "    self.classes = sorted(os.listdir(dataset_path))\n",
        "\n",
        "    self.instances_path = []\n",
        "    self.instances_class = []\n",
        "\n",
        "    # Obtain the paths to all instances of the dataset, as well as their\n",
        "    #   respective dog breeds' labels\n",
        "    for i_class, curr_class in enumerate(self.classes):\n",
        "      class_path = os.path.join(dataset_path, curr_class)\n",
        "      curr_instances_path = [os.path.join(class_path, instance)\n",
        "        for instance in sorted(os.listdir(class_path))]\n",
        "      \n",
        "      self.instances_path += curr_instances_path\n",
        "      self.instances_class += [i_class for i in range(len(curr_instances_path))]\n",
        "\n",
        "    # Initialize preprocessing input pipeline\n",
        "    self.transform = transforms.Compose([\n",
        "      transforms.Resize(256),\n",
        "      transforms.CenterCrop(224),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    '''\n",
        "    Gets the model's input and the respective dog breed index from a dataset\n",
        "      instance.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    index : int\n",
        "      index of the instance to be accessed\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    x : torch.Tensor\n",
        "      tensor refering to the preprocessed sample to be used as an model input\n",
        "    y : int\n",
        "      label refering to the dog breed index of the current instance\n",
        "    '''\n",
        "    \n",
        "    # Access instance's path (`instance_path`)\n",
        "    instance_path = self.instances_path[index]\n",
        "\n",
        "    # Access instance's class (`instance_class`)\n",
        "    instance_class = self.instances_class[index]\n",
        "\n",
        "    # Read image (`img`) and convert to red-green-blue channels (RGB), ensuring\n",
        "    #   the input will have 3 channels\n",
        "    img = Image.open(instance_path).convert('RGB')\n",
        "    \n",
        "    # `x` refers to the image when the preprocessing pipeline (`self.transform`)\n",
        "    #   is applied to the image (`img`)\n",
        "    x = self.transform(img)\n",
        "\n",
        "    # `y` is the instance class (no changes are made)\n",
        "    y = instance_class\n",
        "\n",
        "    return x, y\n",
        "\n",
        "  def __len__(self):\n",
        "    '''\n",
        "    Gets the number of samples presented in the set of images from the initial\n",
        "      100 classes.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    l : int\n",
        "      the length of the dataset\n",
        "    '''\n",
        "    l = len(self.instances_path)\n",
        "\n",
        "    return l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJA4yQ8cRJui",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d49ca14b-e2fc-41e6-9c7a-3419ee2e38d1"
      },
      "source": [
        "# Start initial embeddings and labels list\n",
        "initial_embeddings = []\n",
        "initial_labels = []\n",
        "\n",
        "# Instantiate object for accessing the set of images from the 100-classes\n",
        "#   dataset\n",
        "dataset = ImageDataset(dataset_path)\n",
        "\n",
        "# Create dataloader for accessing the images set in batches\n",
        "dataloader = torch.utils.data.DataLoader(dataset,\n",
        "    batch_size=batch_size, num_workers=n_workers)\n",
        "\n",
        "# Using tqdm to iteratively keep track on the number of iterated batches on the\n",
        "#   console\n",
        "dataloader = tqdm.tqdm(dataloader, position=0, leave=True)\n",
        "\n",
        "# The dataloader is iterated, in order to access all pairs of input-output,\n",
        "#   denoted by `(x, y)`\n",
        "for x, y in dataloader:\n",
        "\n",
        "  # Pass the input tensor to the used device (GPU or CPU)\n",
        "  x = x.to(device)\n",
        "\n",
        "  # Use the model to calculate the embeddings of the input (`embeddings`)\n",
        "  embeddings = model(x)\n",
        "\n",
        "  # Convert the embeddings to a list\n",
        "  embeddings = embeddings.detach().cpu().numpy().tolist()\n",
        "\n",
        "  # Also convert the output to a list\n",
        "  y = y.detach().cpu().numpy().tolist()\n",
        "\n",
        "  # Append the generated embeddings (and their respective dog breed labels) to\n",
        "  #   the total list\n",
        "  initial_embeddings += embeddings\n",
        "  initial_labels += y\n",
        "\n",
        "# Save generated embeddings and labels to a file\n",
        "initial_enroll = {\n",
        "    'embeddings': initial_embeddings,\n",
        "    'labels': initial_labels,\n",
        "    'classes': dataset.classes }\n",
        "with open(initial_enroll_path, 'wb') as f:\n",
        "  pickle.dump(initial_enroll, f)\n",
        "\n",
        "# with open(initial_enroll_path, 'rb') as f:\n",
        "#   initial_enroll = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 543/543 [10:00<00:00,  1.11s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}